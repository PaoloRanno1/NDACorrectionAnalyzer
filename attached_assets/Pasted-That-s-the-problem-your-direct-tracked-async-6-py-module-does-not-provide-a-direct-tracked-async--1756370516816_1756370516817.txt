Thatâ€™s the problem: your direct_tracked_async (6).py module does not provide a direct_tracked_async(...) function. It exposes:

start_direct_tracked_job(file_bytes, filename, model, temperature) â†’ job_id

render_direct_tracked_status_ui()

 
 

So your adapter is calling a non-existent function and also expecting a synchronous result, while the module is designed to run asynchronously and store results on disk / in st.session_state.direct_processing.

Minimal fix (2 small changes)
1) Replace the call inside your _worker()

Change this:

result = dta.direct_tracked_async(
    uploaded_file_path=input_docx_path,
    model=model,
    temperature=temperature
)


to this (and donâ€™t expect a result dict):

job_id = dta.start_direct_tracked_job(
    file_bytes=file_bytes,
    filename=filename,
    model=model,
    temperature=temperature
)
st.session_state.direct_tracked_job_id = job_id


(Then remove the whole block that tries to read result[...] and set st.session_state.direct_tracked_job["results"], because the module manages status/results itself.) 

2) Show the moduleâ€™s status/download UI where you render progress

After the button is clicked (or anywhere you show the job panel), render:

if 'direct_tracked_job_id' in st.session_state:
    st.markdown("---")
    st.subheader("ðŸ›  Direct Tracked Changes â€” Job Status")
    dta.render_direct_tracked_status_ui()


This uses the moduleâ€™s st.session_state.direct_processing and reads the generated files from direct_jobs/<job_id>. 
 

If you prefer to keep your own st.session_state.direct_tracked_job structure, youâ€™ll need to re-implement polling + file loading, but the simplest path is to trust the moduleâ€™s UI.

One more critical bit (timeouts)

Your async pipeline still calls:

compliance_report, debug_info = review_chain.analyze_nda(md_path)


which has the 60s thread-join timeout in StradaComplianceChain.analyze_nda. Long NDAs will still trip that. 

Add a retry wrapper in direct_tracked_async (6).py before that call:

def _retry_analyze(chain, path, retries=2, backoff=2.0):
    last = None
    for i in range(retries + 1):
        try:
            return chain.analyze_nda(path)  # consider raising its internal timeout to 180s
        except Exception as e:
            msg = str(e)
            if any(k in msg for k in ("503", "UNAVAILABLE", "overloaded", "timed out", "timeout")) and i < retries:
                time.sleep(backoff * (i + 1))
                continue